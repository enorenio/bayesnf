{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc7aa9a",
   "metadata": {},
   "source": [
    "# Central Asia AQ/Weather/Mobility Tutorial\n",
    "\n",
    "This notebook demonstrates spatiotemporal prediction on the Central Asia AQ/Weather/Mobility dataset using BayesNF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa082ab7",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/enorenio/bayesnf/blob/main/central_asia_bayesnf.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf0b9e",
   "metadata": {},
   "source": [
    "# 1. Install Required Libraries\n",
    "\n",
    "Install the necessary libraries, including bayesnf, cartopy, contextily, geopandas, and kagglehub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930236f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Libraries\n",
    "!pip install bayesnf\n",
    "!pip -q install cartopy\n",
    "!pip -q install contextily\n",
    "!pip -q install geopandas\n",
    "!pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4ec9c",
   "metadata": {},
   "source": [
    "# 2. Download and Prepare Central Asia Dataset\n",
    "\n",
    "Use kagglehub to download the 'mlbyalex/central-asia-aq-weather-mobility-hourly' dataset.  \n",
    "Set the `file_path` variable to the desired CSV file and load the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"central_asia_aq_weather_mobility_hourly.csv\"  # Update with actual file name if needed\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"mlbyalex/central-asia-aq-weather-mobility-hourly\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documentation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644648f",
   "metadata": {},
   "source": [
    "# 3. Import Libraries\n",
    "\n",
    "Import warnings, contextily, geopandas, jax, matplotlib, numpy, pandas, cartopy.crs, shapely.geometry.Point, and mpl_toolkits.axes_grid1.make_axes_locatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cartopy import crs as ccrs\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9bc23",
   "metadata": {},
   "source": [
    "# 4. Load and Inspect Data\n",
    "\n",
    "Read the dataset into a pandas DataFrame, inspect the first few records, and ensure the data is in long format with appropriate columns for BayesNF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 20 rows to inspect format\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58db716",
   "metadata": {},
   "source": [
    "BayesNF expects the dataframe to be in \"long\" format.  \n",
    "Each row should show a single observation (e.g., `aq_value` or other target) at a given point in time (`datetime` column) and in space (`latitude` and `longitude` columns, which show the centroid of the location).  \n",
    "The `location` column provides a human-readable name for the measurement site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c073c0",
   "metadata": {},
   "source": [
    "# 5. Plot Spatial Snapshots\n",
    "\n",
    "Use geopandas to plot spatial snapshots of the data at different time points, visualizing the distribution of measurements over the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a shapefile for Central Asia, load it here.\n",
    "# For demonstration, we'll assume 'central_asia.shp' is available.\n",
    "region = gpd.read_file('central_asia.shp')  # Update with actual shapefile path\n",
    "\n",
    "df_plot = df.copy()\n",
    "df_plot['centroid'] = df_plot[['longitude','latitude']].apply(Point, axis=1)\n",
    "centroid_to_polygon = {\n",
    "    c: next((g for g in region.geometry.values if g.contains(c)), None)\n",
    "    for c in set(df_plot['centroid'])\n",
    "}\n",
    "df_plot['boundary'] = df_plot['centroid'].replace(centroid_to_polygon)\n",
    "\n",
    "def plot_map(date, ax, value_col='aq_value'):\n",
    "    region.plot(color='none', edgecolor='black', linewidth=1, ax=ax)\n",
    "    ctx.add_basemap(ax, crs=region.crs.to_string(), attribution='', zorder=-1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad='2%', axes_class=plt.matplotlib.axes.Axes)\n",
    "    df_plot_geo = gpd.GeoDataFrame(df_plot, geometry='boundary')\n",
    "    df_plot_geo_t0 = df_plot_geo[df_plot_geo.datetime==date]\n",
    "    df_plot_geo_t0.plot(\n",
    "        column=value_col, alpha=.5, edgecolor='k',\n",
    "        linewidth=1, legend=True, cmap='jet', cax=cax, ax=ax)\n",
    "    gl = ax.gridlines(draw_labels=True, alpha=0)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    ax.set_title(date)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "    figsize=(12.5, 12.5), tight_layout=True)\n",
    "\n",
    "dates = df_plot['datetime'].drop_duplicates().sort_values().iloc[[0, 10, 20, 30]]\n",
    "for ax, date in zip(axes.flat, dates):\n",
    "    plot_map(date, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6cd4a5",
   "metadata": {},
   "source": [
    "# 6. Plot Time Series for Each Location\n",
    "\n",
    "Plot the observed time series for each location to visualize temporal patterns and spatial differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00846cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df.location.unique()\n",
    "fig, axes = plt.subplots(ncols=4, nrows=5, tight_layout=True, figsize=(25,20))\n",
    "for ax, location in zip(axes.flat, locations):\n",
    "    df_location = df[df.location==location]\n",
    "    latitude, longitude = df_location.iloc[0][['latitude', 'longitude']]\n",
    "    ax.plot(df_location.datetime, df_location.aq_value, marker='.', color='k', linewidth=1)\n",
    "    ax.set_title(f'Location: {location} ({longitude:.2f}, {latitude:.2f})')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('AQ Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfc3c4",
   "metadata": {},
   "source": [
    "# 7. Build BayesNF Estimator\n",
    "\n",
    "Construct a BayesNF model (e.g., BayesianNeuralFieldMAP) using relevant feature columns from the Central Asia dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95604986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesnf.spatiotemporal import BayesianNeuralFieldMAP\n",
    "\n",
    "model = BayesianNeuralFieldMAP(\n",
    "  width=256,\n",
    "  depth=2,\n",
    "  freq='H',  # hourly data\n",
    "  seasonality_periods=['D', 'Y'], # daily and yearly\n",
    "  num_seasonal_harmonics=[2, 10],\n",
    "  feature_cols=['datetime', 'latitude', 'longitude'], # time, spatial 1, ..., spatial n\n",
    "  target_col='aq_value',  # update to your target column\n",
    "  observation_model='NORMAL',\n",
    "  timetype='index',\n",
    "  standardize=['latitude', 'longitude'],\n",
    "  interactions=[(0, 1), (0, 2), (1, 2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a42faf",
   "metadata": {},
   "source": [
    "# 8. Fit the Estimator\n",
    "\n",
    "Train the BayesNF estimator on the dataset using the `.fit` method, specifying ensemble size and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9734cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MAP ensemble\n",
    "model = model.fit(\n",
    "    df,\n",
    "    seed=jax.random.PRNGKey(0),\n",
    "    ensemble_size=64,\n",
    "    num_epochs=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8f982",
   "metadata": {},
   "source": [
    "# 9. Plot Training Loss\n",
    "\n",
    "Plot the training loss for each particle in the ensemble to assess convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the training loss for each particle.\n",
    "losses = np.row_stack(model.losses_)\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "ax.plot(losses.T)\n",
    "ax.plot(np.mean(losses, axis=0), color='k', linewidth=3)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Negative Joint Probability')\n",
    "ax.set_yscale('log', base=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b7af6",
   "metadata": {},
   "source": [
    "# 10. Make Predictions\n",
    "\n",
    "Use the model's predict method on a test split of the data, obtaining mean predictions and quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test if not already done\n",
    "# For demonstration, let's assume df_test is available\n",
    "# Otherwise, create a split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "yhat, yhat_quantiles = model.predict(df_test.drop(columns=['aq_value']), quantiles=(0.025, 0.5, 0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b5dba",
   "metadata": {},
   "source": [
    "# 11. Scatter Plot: True vs Predicted\n",
    "\n",
    "Plot a scatter plot comparing true values to predicted values on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3), tight_layout=True)\n",
    "ax.scatter(df_test.aq_value, yhat_quantiles[1], marker='.', color='k')\n",
    "ax.plot([df_test.aq_value.min(), df_test.aq_value.max()], [df_test.aq_value.min(), df_test.aq_value.max()], color='red')\n",
    "ax.set_xlabel('True Value')\n",
    "ax.set_ylabel('Predicted Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3746b3",
   "metadata": {},
   "source": [
    "# 12. Forecasts for Held-Out Locations\n",
    "\n",
    "Plot forecasts for held-out locations, showing observed, predicted, and prediction intervals for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ab123",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df_test.location.unique()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(locations)//2, tight_layout=True, figsize=(16,8))\n",
    "for ax, location in zip(axes.flat, locations):\n",
    "    y_train = df_train[df_train.location==location]\n",
    "    y_test = df_test[df_test.location==location]\n",
    "    ax.scatter(y_train.datetime[-100:], y_train.aq_value[-100:], marker='o', color='k', label='Observations')\n",
    "    ax.scatter(y_test.datetime, y_test.aq_value, marker='o', edgecolor='k', facecolor='w', label='Test Data')\n",
    "    mask = df_test.location.to_numpy() == location\n",
    "    ax.plot(y_test.datetime, yhat_quantiles[1][mask], color='red', label='Median Prediction')\n",
    "    ax.fill_between(y_test.datetime, yhat_quantiles[0][mask], yhat_quantiles[2][mask], alpha=0.5, label='95% Prediction Interval')\n",
    "    ax.set_title('Test Location: %s' % (location,))\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('AQ Value')\n",
    "axes.flat[0].legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
